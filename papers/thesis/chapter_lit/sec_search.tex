\section{Search Strategies}
\label{cha::lit::search}
Given a search graph $G = (V, E)$ and a pair of vertices $s, t \in V$, which 
correspond to the start and target positions of a single agent, 
our objective is to find a path in $G$ from $s$ to $t$.
A large number of strategies have been developed for this purpose. Most fall into
one of three distinct paradigms:
\begin{itemize}
\item{\emph{Blind-search algorithms} which explore the search space in a systematic 
fashion using a fixed node expansion order.}
\item{\emph{Informed-search algorithms} which explore the search space in a systematic
fashion but employ sorting and ranking to ensure that the most promising nodes
are expanded first.}
\item{\emph{Local-search algorithms} which employ heuristic decision-making or mimicry of
natural processes in order to explore only select portions of the search space.}
\end{itemize}

In the course of discussing each paradigm we will sometimes find it useful to
refer to two important properties of search algorithms: \emph{completeness}
and \emph{optimality}.  A search algorithm is \emph{complete} when it
guarantees that it will return a path between the nodes $s$ and $t$ if one
exists in $G$.  Optimality is a stronger property which entails completeness.
A search algorithm is \emph{optimal} if: (i) it guarantees completeness and
(ii) it guarantees that every returned path is a shortest path in $G$.

Note that both properties are defined only with respect to the current search
graph and not the operating environment.  This has some important
ramifications. For example: in order for a complete algorithm to accurately
report whether or not any path exists between $s$ and $t$ it will require a
graph $G$ that preserves solution existence.  Similarly, a path returned by an
optimal search algorithm is not guaranteed to be \emph{truly} optimal in the
environment unless $G$ is constructed in a way that preserves solution
optimality.

\subsection{The Search Process}
\label{cha::lit::search:terms}
Looking for a path between two locations $s$ and $t$ is a process of
repeatedly \emph{expanding} and \emph{generating} nodes from a search graph
$G$.  Expanding a node $n$ is equivalent to performing an action that moves
the agent from its present location to the location associated with node $n$.
As part of this operation the \emph{successors} of $n$ (those nodes
immediately adjacent to $n$ in the graph $G$) become generated. This means
they are evaluated in terms of cost and added to an expansion queue.  This
process continues until either (i) the target node is expanded and a path is
returned or (ii) all the nodes in the expansion queue are exhausted and the
algorithm returns failure.

\subsection{Blind Search}
\label{cha::lit::search::blind}
Blind Search is a systematic search strategy that expands nodes according to 
a fixed order. Often applied to search problems involving small graphs and trees, 
Blind Search algorithms can sometimes find good paths, even optimal paths, much 
faster than more sophisticated search strategies.
 Two classical examples from the literature and Breath First Search 
(BFS)~\citep{moore59} and Depth-First Search (DFS)~\citep{russel03}.  Both of
these algorithms construct a search \emph{tree} which has the start node $s$
at its root. BFS proceeds by expanding all nodes at a given level of the tree
before moving down to the next level. DFS meanwhile expands a node and
immediately recurses down the tree by choosing one of its successors to
explore next\footnote{The selection strategy is usually fixed.}.

Though BFS is a complete and optimal search strategy it requires an amount of 
space and time which increases exponentially with the
depth of the search tree. This means that on challenging real-world problems,
for example involving large graphs and long paths, BFS will often run out 
of time or out of memory well before any solution can be found.  
DFS, by comparison, requires just linear time and
space but lacks any optimality or completeness guarantees. In the worst case
DFS will explore all possible paths in the tree. This means that if the depth
of the tree is unbounded, or if the tree contains repeated nodes, DFS may not
terminate. 

\subsection{Informed Search}
\label{cha::lit::search::informed}
Informed search, sometimes known as best-first search, is a systematic strategy
that assigns a priority to each generated node. The idea is rank nodes by merit 
and to always expand the most promising node first.
In a typical implementation a priority queue, called the 
\emph{open list}, is used to rank generated nodes. A related data structure, 
known as the \emph{closed list}, keeps track of nodes already expanded.

Among the best known and most popular implementations of informed search is 
A{*}~\citep{hart68}. This algorithm computes, for every generated node $n$, a 
priority $f(n)$:

\begin{equation}
f(n) = g(n) + h(n)
\end{equation}

The function $g(n)$ represents the sum of edge costs along the path from the
starting node $s$ to $n$. The function $h(n)$ is a heuristic that estimates the
cost of the path from $n$ to the target node $t$.  Taken together these two
values, $g(n)$ and $h(n)$, provide an estimate of the total cost of a path from
$s$ to $t$ via $n$.  A{*} can be shown to be complete, optimal and optimally
efficient~\citep{dechter85} but only if the heuristic function is both
\emph{admissible} and \emph{consistent}. 
\begin{itemize}
\item Admissible means that $h(n)$ always
lower-bounds the cost of the path from $n$ to $t$. 
\item Consistent means the estimated $f$-cost values computed at each node $n$ and at 
each successor $n'$ are non-decreasing when using the heuristic function $h$; 
i.e.  $h(n) \le c(n, n') + h(n')$. A direct corollary arising from the consistency
property is that along every path the $f$-value of each subsequent node is never 
smaller than its predecessor.
\item Optimally efficient means that no
algorithm which has access to the same information as A{*} can possibly
expand fewer nodes than A{*}.
\end{itemize}
In terms of complexity, A{*} requires $O(|V|)$ space and computes a solution in 
worst-case time $O(|V|\log_2{|V|})$.

\subsection{Local Search}
\label{cha::lit::search::local}
Local search is the name given to a broad class of non-systematic search algorithms.
The central idea is to employ heuristic decision-making to drive search but 
avoid the memory and time overheads associated with blind or informed strategies.
In the case of pathfinding, local search algorithms are typically strategies where:
(i) search is limited to nodes in the immediate vicinity of the agent; 
(ii) search returns only a partial path toward the goal.  Local search
algorithms are often used in real-time settings where pathfinding agents
operate in dynamic or limited information environments, may be subject to
limited computing resources and are expected to react within a constant
time-bound.  Such agents typically apply local search in an iterated manner,
interleaving very short path planning episodes with path executions steps.

Bug algorithms~\citep{choset05} are prototypical examples of local search
applied to pathfinding.  Inspired by insects from
the natural world, these methods navigate in a straight line toward the goal
until an obstacle is encountered. They then circumnavigate the obstacle
(either partially or entirely) in order to find the best ``leave'' point from
which to continue toward the goal.  Bug algorithms are very fast, require
little memory and, though incomplete and suboptimal, are surprisingly
effective on a range of problems (e.g. search spaces containing only convex
obstacles).

More sophisticated examples of localised search techniques can be found among
the members of a large family of algorithms based on
LRTA{*}~\citep{DBLP:journals/ai/Korf90}. Such methods employ a variation of 
informed search that typically expands only a fixed number of
nodes or all nodes up to some fixed $f$-value threshold.  Developed with
iterated execution in mind, these techniques re-use information (e.g. heuristic
values) from previous path planning episodes to improve decision making during
the current episode. Though not usually optimal (in a global sense) algorithms 
based on LRTA{*} are, with few caveats, guaranteed to find a path if one exists. 
Recent works of this type includes:
RIBS~\citep{DBLP:conf/atal/SturtevantBB10},
kNN-LRTA{*}~\citep{DBLP:journals/jair/BulitkoBL10}, 
LRTA{*}+sub~\citep{DBLP:conf/aips/HernandezB11} and 
f-LRTA{*}~\citep{DBLP:conf/ijcai/SturtevantB11}.

\subsection{Performance Enhancements}
\label{cha::lit::search::impl}
A variety of methods have been developed to enhance the performance of the
search strategies we have discussed this far. Such efforts are typically focused
in one of three areas:

\begin{itemize}
\item Reducing the size of the search space.
Typical examples include spatial abstraction, graph pruning, 
symmetry breaking and other approaches that can compact sets of states.
We discuss a number of representative works in Section~\ref{cha::lit::abstraction}
and Section~\ref{cha::lit::symmetry}. Often such approaches involve a 
pre-computation step before any pathfinding can begin.
%and Section~\ref{cha::lit::database}.

\item Better heuristic functions.
Typical examples include: database-driven heuristics, weighted heuristics and 
heuristic portfolios. An overview of such strategies is the subject of 
Section~\ref{cha::lit::heuristics}.

\item Code and memory optimisations. These are discussed in 
Section~\ref{cha::lit::impl}.
\end{itemize}

Each approach has different strengths.  Reducing the size of the search space allows
pathfinding solutions to be found more quickly and permits larger search spaces to be explored.
Better heuristics help to focus the search process toward promising choice-points and often provide
further guidance in the form of lower-bounds. Specialised data structures and other code and memory and
memory optimisations facilitate machine-efficient operations for fetching, sorting and storing sets
of states that need to be explored during search.  These methods are not mutually exclusive.
Indeed, as we will see, they can be and often are very successfully combined.
