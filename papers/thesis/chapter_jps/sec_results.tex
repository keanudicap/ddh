\section{Results}
\label{cha::jps::results}

To evaluate Jump Point Search (JPS) we use a generic implementation of A*
which we adapted to facilitate online neighbour pruning and jump point
identification.  We discuss performance in terms of \emph{speedup}: i.e.
relative improvement to the time taken to solve a given problem, and the
number of nodes expanded, when searching with and without graph pruning
applied to the grid.  Using this metric a search time speedup of 2.0 is twice
as fast while a node expansion speedup of 2.0 indicates half the number of
nodes were expanded.  In each case higher is better.  Figure
\ref{fig::jps::speedup} shows average search time speedups across each of our
four benchmarks. Table \ref{table::jps::nodes} shows average node expansion
speedups; the best results for each column are in bold.

\input chapter_jps/table_nodes

\subsection{Comparison with Swamps}
We begin by comparing JPS to Swamps~\citep{pochter10}: an optimality preserving
pruning technique for speeding up pathfinding.  We used the authors' source
code, and their implementation of A*, and ran all experiments using their
recommended running parameters: a swamp seed radius of 6 and ``no change
limit'' of 2.

As per Figure \ref{fig::jps::speedup}, JPS shows a convincing improvement to
average search times across all benchmarks.  The largest differences are
observed on Baldur's Gate and Dragon Age where JPS reaches the goal between
25-30 times sooner than A* while Swamps attains only a 3-5 times speedup.
Similar trends are observed when looking at Table \ref{table::jps::nodes},
where the improvement to the total number of nodes expanded is even more
pronounced.

Based on these results we conclude that while Swamps are effective for
identifying areas of the map not relevant to reaching the goal, those areas
which remain still require significant effort to search.  JPS uses a much
stronger yet orthogonal strategy to prove that many nodes expanded by Swamps
can be ignored.  As the two ideas appear complementary we posit that they
could be easily combined: first, apply a Swamps-based decomposition to prune
areas not relevant to the current search.  Then, use JPS to search the
remaining portions of the map.

\begin{figure*}[t!]
   \begin{center}
	   \includegraphics[width=0.98\columnwidth]
		{chapter_jps/diagrams/speedup.pdf}
   \end{center}
   \caption{Average A* search time speedup on our each of our four benchmarks. }

\label{fig::jps::speedup}
\end{figure*}


\subsection{Comparison with HPA*}
Next, we compare JPS to the HPA* algorithm~\citep{botea04}.  Though
sub-optimal, HPA* is very fast and widely applied in video games.  To evaluate
HPA* we measure the total cost of insertion and hierarchical search. We did
not refine any abstract paths, assuming instead that a database of
pre-computed intra-cluster paths was available. Such a configuration
represents the fastest generic implementation of HPA* but requires additional
memory overheads.  While searching we used a single-level abstraction
hierarchy and a fixed cluster size of $10\times10$.  These settings are
recommended by the original authors who note that larger clusters and more
levels are often of little benefit.

As per Figure \ref{fig::jps::speedup}, JPS is shown to be highly competitive
with HPA*.  On Adaptive Depth, Baldur's Gate and Rooms, JPS has a clear
advantage -- improving on HPA* search times by several factors in some cases.
On the Dragon Age benchmark jump points have a small advantage for problems of
length $< 500$ but for longer instances there is very little between the two
algorithms.  Table \ref{table::jps::nodes} provides further insight: although
searching with jump points expands significantly fewer nodes than HPA*, each
such operation takes longer.

We conclude that JPS is a competitive substitute for HPA* and, for a wide
variety of problems, can help to find solutions significantly faster.  HPA*
can still be advantageous, particularly if a memory overhead is acceptable and
optimality is not important, but only if the cost of inserting the start and
goal nodes into the abstract graph (and possibly refinement, if a path
database is not available), can be sufficiently amortized over the time
required to find an abstract path.  One direction for further work could be to
use jump point pruning to speed up HPA*: for example during insertion and
refinement.

