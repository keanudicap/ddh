\section{Search Strategies}
\label{cha::lit::search}
Given a search graph $G$ and a pair of vertices $s$ and $t$, which correspond to the 
start and target positions of a single agent, our objective is to find a path in $G$
from $s$ to $t$.
A large number of strategies have been developed for this purpose. Most fall into
one of three distinct paradigms:
\begin{itemize}
\item{\emph{Blind-search algorithms} which explore the solution space in a systematic fashion.}
\item{\emph{Informed-search algorithms} which employ lower-bounds to improve the 
efficiency of systematic search.}
\item{\emph{Local-search algorithms} which employ heuristic decision-making or mimicry of
natural processes in order to explore only select portions of the solution space.}
\end{itemize}

In the next sections we will discuss each paradigm in turn. In doing so we will sometimes
find it useful to refer to two important properties of search algorithms: \emph{completeness} 
and \emph{optimality}.
We say that a search algorithm is \emph{complete} when it guarantees that it will return a
solution if there exists a path between nodes $s$ and $t$ in $G$. 
Optimality is a similar but stronger property which entails completeness. 
We will say that a search algorithm is \emph{optimal} if it guarantees that every solution it 
returns is also a shortest path from $s$ to $t$ in $G$. 

Both properties are defined only with respect to the current search graph $G$.
This has some important ramifications. For example: 
in order for a complete algorithm to accurately report whether or not any path exists between 
$s$ and $t$ it will require a graph $G$ that preserves solution existence.
Similarly, a path returned by an optimal search algorithm
is not guaranteed to be \emph{truly} optimal (that is, optimal with respect to the operating environment 
of the agent) unless $G$ is constructed in a way that preserves solution optimality.

\subsection{The Search Process}
\label{cha::lit::search:terms}
Looking for a path between two locations $s$ and $t$ is a process of repeatedly
\emph{expanding} and \emph{generating} nodes from a search graph $G$; 
Expanding a node $n$ is equivalent to performing an action that moves the agent 
from its present location to the location associated with node $n$.
As part of this operation the \emph{successors} of $n$ (those nodes immediately 
adjacent to $n$ in the graph $G$) become generated. This means they are evaluated 
in terms of cost and, depending on the search strategy at hand, they are either
assigned a priority and added to an expansion queue or they are expanded
immediately in a recursive fashion.  This process continues until either (i)
target node is reached and a path is returned or (ii) all the nodes in the
expansion queue are exhausted and the algorithm returns failure.

\subsection{Blind Search}
\label{cha::lit::search::blind}
Blind search is a systematic search strategy that expand nodes from the 
graph in a fixed order. Two classical examples are Breadth-First Search (BFS) and 
Depth-First Search (DFS). 

Both algorithms construct a search \emph{tree} which has the start node $s$ at its root. 
BFS proceeds by expanding all nodes at a given level of the tree
before moving down to the next level. DFS meanwhile recurses down the tree immediately 
by expanding a node as soon as it generates it.
BFS is a complete and optimal strategy but it is not very efficient; it requires
an amount of space and time which increases exponentially with the depth at which 
the target node is found in the search tree.
By comparison, DFS is much faster and much more memory efficient: it requires just
linear time to explore a full branch of the tree, from root to leaf, and it keeps in 
memory only the nodes found along that branch. Unfortunately DFS lacks any optimality or 
completeness guarantees and in the worst case it will expand all nodes in the tree.
Worse, if the depth of the tree is unbounded, or if it contains cycles, 
DFS will not terminate.

\subsection{Informed Search}
\label{cha::lit::search::informed}
Informed search, sometimes known as best-first search, is a systematic strategy
that expands nodes according to a given priority or $f$-value. 
For every node $n$ we have:

\begin{equation}
f(n) = g(n) + h(n)
\end{equation}

The function $g(n)$ returns the sum of edge costs along the path from $s$ to $n$.
Meanwhile, $h(n)$ is heuristic function used to estimate the cost of the path 
from $n$ to the target node $t$. When taken together the two values, 
$g(n)$ and $h(n)$, provide an estimate of the total cost of a path from $s$ to 
$t$ via node $n$.
The central idea behind informed search is to always expand the most promising node 
first. This is achieved by way of a priority queue (often a minimum heap) 
called the \emph{open list}. A related data structure, known as the \emph{closed list},
is often employed at the same time. Its purpose is to avoid duplicated effort by keeping
track of which nodes have already been expanded. 

The canonical best-first algorithm is Dijkstra's Algorithm (DA)~\cite{dijkstra59}. It can be 
described as using a highly optimistic heuristic function that always returns zero.
Compared to BFS and DFS, DA has several compelling advantages: it is complete, optimal,
requires only linear space and computes a solution in worst-case time $O(n\log{2}{n})$ 
(in this context $n$ refers to the total number of nodes in the search graph $G$).
DA is a seminal work in the search literature; it is among the best known and most
effective strategies for solving pathfinding problems and continues to be widely
used today. Only one approach is known that can achieve better results: A*~\cite{hart68}.


\subsection{Local Search}
\label{cha::lit::search::local}

